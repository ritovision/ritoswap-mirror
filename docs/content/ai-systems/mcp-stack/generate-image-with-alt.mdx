---
title: MCP Tool · generate_image_with_alt
description: Streams image bytes, alt text, and hydrator payloads for inline rendering.
---

import { Callout, Table } from 'nextra/components'

# `generate_image_with_alt`

Defined in `dapp/app/lib/mcp/tools/image-generate-workflow.ts`, this tool centralizes OpenAI image creation and the client-side delivery contract.

## Pipeline Highlights

- **Input schema** — accepts a `prompt` plus an optional `name`. Sizes/quality are fixed by `aiServerConfig.image.defaults` to keep runtime predictable.
- **Generation** — `callOpenAIImage` is the sole generator path today; it enforces the OpenAI provider and falls back to fetching the signed URL when `b64_json` is absent.
- **Alt Text** — `generateAltText` uses the configured vision provider (`openai` or `lmstudio`) so every image ships with accessible copy even though the pixels never touch disk.
- **Streaming** — the handler pushes JSON first (`{ kind: 'store-image', name, width, height, dataBase64 }`) and then the `<img src="store://...">` text segment so hydrators can populate caches before the transcript renders.

## Image Delivery

Images generated by tools are never stored server-side. The workflow (`image-generate-workflow.ts`) streams a base64 payload through SSE, marks it with `kind: 'store-image'`, and inserts a placeholder `<img src="store://image/...">` tag in the text portion. The client’s hydration hook writes the data into memory so `parseContentWithMedia.ts` can render it inline.

```ts
// dapp/app/lib/mcp/tools/image-generate-workflow.ts
const imageGenerateWorkflow: Tool<Params> = {
  name: 'generate_image_with_alt',
  description: 'Generate an image and emit a store:// payload + alt text.',
  async handler({ prompt, name }) {
    const { pngBase64, w, h } = await callOpenAIImage(prompt);
    const alt = await generateAltText(`data:image/png;base64,${pngBase64}`);
    const fileName = uniqueName(name);
    const json = jsonResult({
      kind: 'store-image',
      name: fileName,
      mime: 'image/png',
      width: w,
      height: h,
      alt,
      dataBase64: pngBase64,
    });
    const text = textResult(
      `<img src="store://image/${fileName}" alt="${alt.replace(/"/g, '&quot;')}" width="${w}" height="${h}" />`,
    );
    return { content: [...json.content, ...text.content] };
  },
};
```

## Presenter Behavior

`dapp/components/chatBot/ToolActivity/catalog/presenters/generate_image_with_alt.presenter.ts` keeps the UI minimal:

<Table>
  <thead>
    <tr>
      <th>Status</th>
      <th>Label</th>
      <th>Details</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>pending</td>
      <td>`Generating image…`</td>
      <td>No body text; indicates the tool is still queueing.</td>
    </tr>
    <tr>
      <td>success</td>
      <td>`Image ready`</td>
      <td>Shows `name (width×height)` when available so the user knows what asset arrived.</td>
    </tr>
    <tr>
      <td>error</td>
      <td>`Image failed`</td>
      <td>Surfaces the raw error text (e.g., provider outage) for quick troubleshooting.</td>
    </tr>
  </tbody>
</Table>

## Playground Demo

Submit message to see the tool use process simulated.

<div style={{ width: '100%', height: 820, margin: '2rem 0' }}>
  <iframe
    src="/storybook-static/index.html?path=/story/chatbot-toolchips-inchat--generate-image-interactive&nav=0"
    width="100%"
    height="100%"
    style={{ border: '1px solid rgba(255,255,255,0.1)', borderRadius: '10px' }}
    title="ChatBot/ToolChips/InChat - Generate Image (Playground)"
    loading="lazy"
    tabIndex={-1}
  />
</div>

## Ties to the Frontend

<Callout type="info">
`useHydrateToolImages.ts` listens for the `{ kind: 'store-image' }` JSON emitted by this tool. That hook writes the base64 bytes into the `useLocalImageStore`, so the `<img src="store://image/...">` tag rendered in the chat stream resolves instantly without another network hop.
</Callout>
